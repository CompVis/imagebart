model:
  base_learning_rate: 0.0625
  target: imagebart.models.diffusion.DecoderOnlyDenoiser
  params:
    first_stage_key: "image"
    monitor: "val/loss"
    n_scales: 4
    single_scale: 4
    top_k: 548
    alpha: 1.0  # soft only
    redraw_prob: geometric
    use_ema: True

    scheduler_config:
      target: imagebart.lr_scheduler.LambdaWarmUpCosineScheduler
      params:
        verbosity_interval: 0   # 0 or negative to disable
        warm_up_steps: 10000
        max_decay_steps: 1500001
        lr_start: 2.5e-6
        lr_max: 1.0e-4
        lr_min: 1.0e-8

    transformer_config:
      target: imagebart.modules.transformer.mingpt.GPT
      params:
        vocab_size: 548
        block_size: 256  # 256 data tokens - 1 + 1 scale token
        n_layer: 26
        n_head: 16
        n_embd: 800

    first_stage_config:
      target: imagebart.models.vqgan.VQGANWrapper
      params:
        ckpt_path: vqgan/vqgan-ffhq.ckpt
        remap: "data/vqgan_indices/ffhq_indices.npy"
        sane_index_shape: True
        embed_dim: 256
        n_embed: 1024
        ddconfig:
          double_z: False
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [ 1,1,2,2,4 ]  # num_down = len(ch_mult)-1
          num_res_blocks: 2
          attn_resolutions: [ 16 ]
          dropout: 0.0
        lossconfig:
          target: taming.modules.losses.vqperceptual.DummyLoss

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 16
    wrap: False
    train:
      target: taming.data.faceshq.FFHQTrain
      params:
        size: 256
    validation:
      target: taming.data.faceshq.FFHQValidation
      params:
        size: 256

lightning:
  callbacks:
    image_logger:
      target: main.ImageLogger
      params:
        batch_frequency: 1000
        max_images: 4
        increase_log_steps: False
  trainer:
    benchmark: True
