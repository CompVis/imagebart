model:
  base_learning_rate: 0.0625
  target: imagebart.models.diffusion.DecoderOnlyDenoiser
  params:
    first_stage_key: image
    monitor: val/loss
    n_scales: 2
    single_scale: 2
    top_k: 548
    alpha: 1.0
    redraw_prob: ffhq_bernoulli_PSIM
    use_ema: true
    scheduler_config:
      target: imagebart.lr_scheduler.LambdaWarmUpCosineScheduler
      params:
        verbosity_interval: 0
        warm_up_steps: 10000
        max_decay_steps: 1500001
        lr_start: 2.5e-06
        lr_max: 0.0001
        lr_min: 1.0e-08
    transformer_config:
      target: imagebart.modules.transformer.mingpt.GPT
      params:
        vocab_size: 548
        block_size: 256
        n_layer: 36
        n_head: 16
        n_embd: 1216
    first_stage_config:
      target: imagebart.models.vqgan.VQGANWrapper
      params:
        ckpt_path: vqgan/vqgan-ffhq.ckpt
        remap: data/vqgan_indices/ffhq_indices.npy
        sane_index_shape: true
        embed_dim: 256
        n_embed: 1024
        ddconfig:
          double_z: false
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 1
          - 2
          - 2
          - 4
          num_res_blocks: 2
          attn_resolutions:
          - 16
          dropout: 0.0
        lossconfig:
          target: taming.modules.losses.vqperceptual.DummyLoss

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 18
    wrap: false
    train:
      target: taming.data.faceshq.FFHQTrain
      params:
        size: 256
    validation:
      target: taming.data.faceshq.FFHQValidation
      params:
        size: 256
